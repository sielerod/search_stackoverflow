{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595126186130",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unidecode\n",
    "\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "#from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.stem import SnowballStemmer #Stemming: Porter2 >  more aggressive than the Porter stemmer, Slightly faster, \n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"I love watching movies when it's cold outside\""
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "document_1 = \"I love watching movies when it's cold outside\"\n",
    "document_2 = \"Toy Story is the best animation movie ever, I love it!\"\n",
    "document_3 = \"Watching horror movies alone at night is really scary\"\n",
    "document_4 = \"He loves to watch films filled with suspense and unexpected plot twists\"\n",
    "document_5 = \"My mom loves to watch movies. My dad hates movie theaters. My brothers like any kind of movie. And I haven't watched a single movie since I got into college\"\n",
    "\n",
    "documents = [document_1, document_2, document_3, document_4, document_5]\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'i love watching movies when its cold outside'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "def clean_text (text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) #remove todas as pontuações: '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    text = text.replace('\\n',' ').strip() \n",
    "    text = text.lower()\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text\n",
    "\n",
    "clean_text(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redução das palavras para sua raiz (stemming), remoção de stopwords e palavras com menos de 2 caracteres, e criação do vocabulário com a quantidade de ocorrência de cada palavra em todos os documentos\n",
    "def vocabulary_stemming(documents):\n",
    "    docs_stem_words = []\n",
    "    vocabulary = {}\n",
    "    stop_words = stopwords.words('english')\n",
    "    snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    for index in range(len(documents)):\n",
    "        text = documents[index]\n",
    "        tokentext = word_tokenize(clean_text(text))\n",
    "        stem_words  = [snowball_stemmer.stem(word) for word in tokentext if not word in stop_words and len(word) > 2 and word not in string.punctuation]\n",
    "        docs_stem_words.append(stem_words)\n",
    "\n",
    "        #Inicializa vocabulário sem repetição de palavras\n",
    "        for word in stem_words:\n",
    "            vocabulary[word] = 0\n",
    "\n",
    "    #Contabiliza ocorrência de cada palavra em todos os documentos\n",
    "    for words in docs_stem_words:\n",
    "        for word in words:\n",
    "            vocabulary[word] += 1\n",
    "    \n",
    "    return vocabulary, docs_stem_words\n",
    "\n",
    "vocabulary, docs_stem_words = vocabulary_stemming(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outra opção de tratamento na construção do vocabulário e frequencias\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "tokens = sum([word_tokenize(clean_text(document)) for document in documents], [])\n",
    "stem_words  = [snowball_stemmer.stem(word) for word in tokens if not word in stop_words and len(word) > 2 and word not in string.punctuation]\n",
    "words_frequency2 = FreqDist(stem_words)\n",
    "words_frequency2.plot(30, cumulative = False)\n",
    "words_frequency1 = FreqDist(tokens)\n",
    "words_frequency1.plot(30, cumulative = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['love', 'watch', 'movi', 'cold', 'outsid'],\n ['toy', 'stori', 'best', 'anim', 'movi', 'ever', 'love'],\n ['watch', 'horror', 'movi', 'alon', 'night', 'realli', 'scari'],\n ['love', 'watch', 'film', 'fill', 'suspens', 'unexpect', 'plot', 'twist'],\n ['mom',\n  'love',\n  'watch',\n  'movi',\n  'dad',\n  'hate',\n  'movi',\n  'theater',\n  'brother',\n  'like',\n  'kind',\n  'movi',\n  'havent',\n  'watch',\n  'singl',\n  'movi',\n  'sinc',\n  'got',\n  'colleg']]"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "docs_stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_items([('love', 4), ('watch', 5), ('movi', 7), ('cold', 1), ('outsid', 1), ('toy', 1), ('stori', 1), ('best', 1), ('anim', 1), ('ever', 1), ('horror', 1), ('alon', 1), ('night', 1), ('realli', 1), ('scari', 1), ('film', 1), ('fill', 1), ('suspens', 1), ('unexpect', 1), ('plot', 1), ('twist', 1), ('mom', 1), ('dad', 1), ('hate', 1), ('theater', 1), ('brother', 1), ('like', 1), ('kind', 1), ('havent', 1), ('singl', 1), ('sinc', 1), ('got', 1), ('colleg', 1)])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "vocabulary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_items([('love', [[0, 1], [1, 1], [3, 1], [4, 1]]), ('watch', [[0, 1], [2, 1], [3, 1], [4, 2]]), ('movi', [[0, 1], [1, 1], [2, 1], [4, 4]]), ('cold', [[0, 1]]), ('outsid', [[0, 1]]), ('toy', [[1, 1]]), ('stori', [[1, 1]]), ('best', [[1, 1]]), ('anim', [[1, 1]]), ('ever', [[1, 1]]), ('horror', [[2, 1]]), ('alon', [[2, 1]]), ('night', [[2, 1]]), ('realli', [[2, 1]]), ('scari', [[2, 1]]), ('film', [[3, 1]]), ('fill', [[3, 1]]), ('suspens', [[3, 1]]), ('unexpect', [[3, 1]]), ('plot', [[3, 1]]), ('twist', [[3, 1]]), ('mom', [[4, 1]]), ('dad', [[4, 1]]), ('hate', [[4, 1]]), ('theater', [[4, 1]]), ('brother', [[4, 1]]), ('like', [[4, 1]]), ('kind', [[4, 1]]), ('havent', [[4, 1]]), ('singl', [[4, 1]]), ('sinc', [[4, 1]]), ('got', [[4, 1]]), ('colleg', [[4, 1]])])"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "#Criar índice invertido\n",
    "def invertedIndex(vocabulary, docs_stem_words): \n",
    "    invertedList = dict()\n",
    "    for term in vocabulary:\n",
    "        invertedList[term] = list()\n",
    "        index = 0\n",
    "        for stem_words in docs_stem_words:\n",
    "            frequencia = 0\n",
    "            for word in stem_words:\n",
    "                if word == term:\n",
    "                    frequencia += 1\n",
    "            if frequencia > 0:\n",
    "                invertedList[term].append([index, frequencia])\n",
    "            index += 1\n",
    "    return invertedList\n",
    "\n",
    "invertedList = invertedIndex(vocabulary, docs_stem_words)\n",
    "invertedList.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Vocabulary     ni      Inverted Lists\n0       love           4       [[0, 1], [1, 1], [3, 1], [4, 1]]\n1       watch          5       [[0, 1], [2, 1], [3, 1], [4, 2]]\n2       movi           7       [[0, 1], [1, 1], [2, 1], [4, 4]]\n3       cold           1       [[0, 1]]\n4       outsid         1       [[0, 1]]\n5       toy            1       [[1, 1]]\n6       stori          1       [[1, 1]]\n7       best           1       [[1, 1]]\n8       anim           1       [[1, 1]]\n9       ever           1       [[1, 1]]\n10      horror         1       [[2, 1]]\n11      alon           1       [[2, 1]]\n12      night          1       [[2, 1]]\n13      realli         1       [[2, 1]]\n14      scari          1       [[2, 1]]\n15      film           1       [[3, 1]]\n16      fill           1       [[3, 1]]\n17      suspens        1       [[3, 1]]\n18      unexpect       1       [[3, 1]]\n19      plot           1       [[3, 1]]\n20      twist          1       [[3, 1]]\n21      mom            1       [[4, 1]]\n22      dad            1       [[4, 1]]\n23      hate           1       [[4, 1]]\n24      theater        1       [[4, 1]]\n25      brother        1       [[4, 1]]\n26      like           1       [[4, 1]]\n27      kind           1       [[4, 1]]\n28      havent         1       [[4, 1]]\n29      singl          1       [[4, 1]]\n30      sinc           1       [[4, 1]]\n31      got            1       [[4, 1]]\n32      colleg         1       [[4, 1]]\n"
    }
   ],
   "source": [
    "#Exibe os dados formatados\n",
    "fmt = '{:<8}{:<15}{:<8}{}'\n",
    "\n",
    "print(fmt.format('', 'Vocabulary', 'ni', 'Inverted Lists'))\n",
    "for i, (vocab, ni, ocurrencies) in enumerate(zip(vocabulary.keys(), vocabulary.values(), invertedList.values())):\n",
    "    print(fmt.format(i, vocab, ni, ocurrencies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_query(self, query):\n",
    "    docs_index = [self[term] for term in query.split(' ') if term in self.keys()]\n",
    "    return docs_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[[0, 1], [2, 1], [3, 1], [4, 2]], [[0, 1], [1, 1], [3, 1], [4, 1]]]"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "lookup_query(invertedList,'watch with love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['love', 'watch', 'movi', 'cold', 'outsid', 'toy', 'stori', 'best', 'anim', 'ever', 'horror', 'alon', 'night', 'realli', 'scari', 'film', 'fill', 'suspens', 'unexpect', 'plot', 'twist', 'mom', 'dad', 'hate', 'theater', 'brother', 'like', 'kind', 'havent', 'singl', 'sinc', 'got', 'colleg'])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}